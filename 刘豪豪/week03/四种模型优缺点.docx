Bert模型：
核心原理：基于Transformer的深度双向预训练模型，可以理解上下文语义
优点：语义理解比较深，通用性强，可用于智能客服方面分析客户的意图，为客服人员提供一些建议
缺点：计算资源需求大，有时候需要进行微调，在处理长文本时需要进行截断


Prompt（大语言模型）：
核心原理：通过自然语言引导大语言模型完成相应的任务
优点：灵活性高，不需要训练，可以自然交互，识别驾驶员的需求并执行任务
缺点：提示词设计需要一定的技巧，交互会产生成本


Regex（正则表达式）模型：
核心原理：基于预定义的规则进行字符串匹配
优点：可以精确匹配，速度快并且消耗的资源也比较少
缺点：无法理解语义，规则编写复杂且不方便维护，对于复杂的任务性能表现不好


TF-IDF模型：
核心原理：基于词频统计，评估词语在文档中的重要性
优点：计算简单，不需要复杂的训练
缺点：无法理解语义，会忽略词序，不能理解一词多义和同义词
