1. 正则规则模型 (regex_rule.py)
优点：
执行效率极高：基于正则表达式匹配，几乎无延迟，远低于400毫秒要求
可解释性强：每个分类决策都有明确的规则依据，便于调试和优化
实现简单：代码逻辑清晰，维护成本低
确定性高：相同输入总是产生相同输出，稳定性好
无需训练：可立即部署使用，适合快速验证
缺点：
覆盖范围有限：仅能识别预设关键词，无法处理语义相近但用词不同的表达
规则爆炸：随着类别增多，需要维护大量正则规则，扩展困难
泛化能力差：对于同义词、近义词、口语化表达识别效果差
准确性受限：很难达到项目要求的95%准确率
维护困难：规则冲突和优先级管理复杂
2. TF-IDF + 机器学习模型 (tfidf_ml.py)
优点：
统计特性好：TF-IDF能有效表示词语重要性，相比单纯词频更合理
泛化能力中等：基于训练数据学习模式，能处理一定变体表达
性能良好：向量化和预测速度快，容易满足400毫秒延迟要求
可解释性较好：特征权重可分析，模型决策过程相对透明
资源占用少：模型体积小，内存占用低，适合资源受限环境
训练成本低：传统机器学习算法训练时间短
缺点：
语义理解弱：无法捕捉词汇间的语义关系，如"汽车"和"轿车"
特征局限性：仅基于词汇层面特征，忽略语法和句法信息
分词依赖：中文分词准确性直接影响模型性能
词序信息丢失：TF-IDF向量不保留词语顺序信息
准确率上限：相比深度学习模型，准确率可能存在天花板
3. BERT模型 (bert.py)
优点：
语义理解强：双向Transformer架构能充分理解上下文语义
准确率高：预训练+微调范式通常能达到很高的分类准确率
泛化能力强：能处理多种表达方式和同义转换
特征提取全面：自动学习多层次的语言特征
适应性好：对领域特定数据适应性强
鲁棒性佳：对拼写错误、语法变化有一定容忍度
缺点：
计算资源消耗大：需要GPU加速，内存占用高（数百MB到GB级别）
推理延迟高：可能难以满足400毫秒延迟要求，特别是CPU推理
模型复杂度高：实现和部署复杂，需要深度学习框架支持
黑盒性质：内部决策过程不透明，可解释性差
微调成本：需要标注数据进行领域适应微调
版本依赖：对transformers库等依赖版本敏感
4. 大语言模型 (GPT-based, prompt.py)
优点：
语义理解最强：具备强大的上下文理解和推理能力
零样本学习：无需特定领域的训练数据即可工作
动态适应：通过提示词工程可灵活调整行为
示例学习：结合相似样例提升分类准确性
表达多样性处理：能很好处理各种表达方式
上下文感知：考虑语境信息进行判断
缺点：
延迟严重：API调用往返时间长，极难满足400毫秒要求
成本高昂：按次调用API，大规模使用费用高
稳定性差：输出可能不稳定，同一输入可能有不同结果
隐私风险：敏感数据需发送到外部服务器
幻觉风险：可能产生不符合实际的输出
网络依赖：需要稳定的网络连接
可控性差：输出格式可能不完全符合预期