# 文本分类模型对比

本文档提供了四个文本分类模型的详细对比，涵盖了精度、速度、资源消耗、可维护性及适用场景等方面。以下是各个模型的具体介绍和优缺点分析。

## 1. BERT 微调模型 (`model_for_bert`)

### 原理
基于预训练 BERT + 微调分类头。

### 优点
- **高精度**：语义理解强，适合复杂意图。
- **端到端**：无需特征工程。
- **鲁棒性好**：对同义词、错别字有一定容忍度。

### 缺点
- **慢**：推理需要 GPU，单条请求耗时约 50–200ms。
- **资源重**：模型较大（>400MB），部署成本较高。
- **冷启动**：需加载完整模型。

### 适用场景
对精度要求高、有 GPU 资源、离线或低并发场景。

---

## 2. 大模型 + RAG (`model_for_gpt`)

### 原理
使用 TF-IDF 检索相似样本 → 构造 prompt → 调用 LLM（如 ChatGLM/Qwen）。

### 优点
- **极强泛化**：能处理训练集未见的新类别（依靠 prompt）。
- **可解释性**：prompt 中可见参考样例。
- **灵活性**：无需重新训练，修改 prompt 即可调整逻辑。

### 缺点
- **极慢**：每次调用需联网或使用本地大模型，耗时约 1–5 秒。
- **不稳定**：可能产生“幻觉”、输出格式错误。
- **昂贵/资源密集**：依赖大模型服务（API 费用或本地显存）。

### 适用场景
探索性任务、零样本/少样本、允许延迟的高价值场景。

---

## 3. 规则正则 (`model_for_regex`)

### 原理
关键词/正则匹配。

### 优点
- **极速**：微秒级响应。
- **100% 可控**：规则明确，无黑盒。
- **零依赖**：纯 Python 实现，内存占用极小。

### 缺点
- **覆盖有限**：只能匹配已知模式。
- **维护难度大**：规则膨胀后难以管理。
- **脆弱性**：同义替换、错别字即失效。

### 适用场景
高频、确定性高的简单意图（如“查天气”、“打电话”）。

---

## 4. TF-IDF + 传统 ML (`model_for_tfidf`)

### 原理
TF-IDF 向量化 + 分类器（如 SVM/LogisticRegression）。

### 优点
- **快**：CPU 推理，毫秒级响应。
- **轻量**：模型小（<10MB）。
- **稳定性**：无随机性，结果可复现。

### 缺点
- **语义理解弱**：无法理解“导航去北京” ≈ “带我去首都”。
- **依赖分词**：中文分词质量影响较大。
- **特征稀疏**：长尾词效果较差。

### 适用场景
中等精度要求、高并发、无 GPU 的生产环境。